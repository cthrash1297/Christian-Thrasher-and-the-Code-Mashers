{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786b0ea3-8b47-4a2e-b4d1-2237672a9a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /opt/conda/lib/python3.11/site-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from opendatasets) (4.67.1)\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.11/site-packages (from opendatasets) (1.7.4.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from opendatasets) (8.1.7)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (6.1.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (3.4.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (3.10)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (4.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (69.5.1)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2.2.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.19.0)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.9.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, optree, opt-einsum, ml-dtypes, google-pasta, gast, astunparse, keras, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 keras-3.9.1 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets\n",
    "!pip install pandas\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d80011a-6c88-496c-aa85-a3870b1e0528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  sharifuln38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od \n",
    "import pandas \n",
    "\n",
    "od.download( \n",
    "    \"https://www.kaggle.com/datasets/msambare/fer2013/data\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b784d2-9cb0-4444-bec2-ef5e2fae3335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the files in the downloaded folder\n",
    "dataset_path = \"fer2013\"\n",
    "os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a33c57-7173-41dc-a532-12aa01c3baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Checking if CUDA is available\n",
    "flag_cuda = torch.cuda.is_available()\n",
    "\n",
    "if not flag_cuda:\n",
    "    print('Using CPU')\n",
    "else:\n",
    "    print('Using GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8d29c84-49a3-478a-bd30-4d98218318b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure single-channel grayscale\n",
    "    transforms.Resize((48, 48)),  # Resize to match FER2013 dimensions\n",
    "    transforms.ToTensor(),  # Convert PIL image to PyTorch tensor ✅\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "# Load FER2013 dataset\n",
    "# Load train and test datasets\n",
    "train_dataset = datasets.ImageFolder(root=\"./fer2013/train\", transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root=\"./fer2013/test\", transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2db774f-3b67-44ef-ae02-ace182407ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "074954f7-8544-4bbe-9978-3b268074e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset sizes\n",
    "train_N = len(train_dataset)\n",
    "valid_N = len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "458f763d-5f24-4436-a58f-a02d716943ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "n_classes = 7  # FER2013 has 7 emotions\n",
    "IMG_CHS = 1  # Grayscale images\n",
    "kernel_size = 3\n",
    "flattened_img_size = 75 * 3 * 3\n",
    "\n",
    "# Define the CNN Model\n",
    "model = nn.Sequential(\n",
    "    # First convolution\n",
    "    nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1),  # 25 x 48 x 48\n",
    "    nn.BatchNorm2d(25),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),  # 25 x 24 x 24\n",
    "    \n",
    "    # Second convolution\n",
    "    nn.Conv2d(25, 50, kernel_size, stride=1, padding=1),  # 50 x 24 x 24\n",
    "    nn.BatchNorm2d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.MaxPool2d(2, stride=2),  # 50 x 12 x 12\n",
    "    \n",
    "    # Third convolution\n",
    "    nn.Conv2d(50, 75, kernel_size, stride=1, padding=1),  # 75 x 12 x 12\n",
    "    nn.BatchNorm2d(75),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),  # 75 x 6 x 6\n",
    "    \n",
    "    # Flatten to Dense\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(75 * 6 * 6, 512),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, n_classes)  # Output 7 classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9818666d-f5e1-4c25-9887-5fde6c377cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if flag_cuda else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25169d9b-d62f-4693-9b16-f6fac8cda1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab039a74-e60e-4692-92ce-87f517faeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate batch accuracy\n",
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "838da5b6-f4cc-42fc-b6e6-5e0bd7772bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    \n",
    "    print(f'Valid - Loss: {loss:.4f} Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76a84054-e67f-404b-a2af-43a89438a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    \n",
    "    print(f'Train - Loss: {loss:.4f} Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49bd1257-7ec4-4672-bf87-10a3cd085d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n",
      "Train - Loss: 1437.9203 Accuracy: 0.3693\n",
      "Valid - Loss: 310.0239 Accuracy: 0.4692\n",
      "Epoch: 2/20\n",
      "Train - Loss: 1226.5922 Accuracy: 0.4725\n",
      "Valid - Loss: 287.1896 Accuracy: 0.5106\n",
      "Epoch: 3/20\n",
      "Train - Loss: 1138.3527 Accuracy: 0.5154\n",
      "Valid - Loss: 281.0195 Accuracy: 0.5192\n",
      "Epoch: 4/20\n",
      "Train - Loss: 1072.5078 Accuracy: 0.5419\n",
      "Valid - Loss: 263.3839 Accuracy: 0.5522\n",
      "Epoch: 5/20\n",
      "Train - Loss: 1025.3668 Accuracy: 0.5648\n",
      "Valid - Loss: 267.7942 Accuracy: 0.5393\n",
      "Epoch: 6/20\n",
      "Train - Loss: 978.2644 Accuracy: 0.5843\n",
      "Valid - Loss: 253.9451 Accuracy: 0.5733\n",
      "Epoch: 7/20\n",
      "Train - Loss: 934.9874 Accuracy: 0.6041\n",
      "Valid - Loss: 251.6647 Accuracy: 0.5747\n",
      "Epoch: 8/20\n",
      "Train - Loss: 896.0227 Accuracy: 0.6214\n",
      "Valid - Loss: 246.1778 Accuracy: 0.5860\n",
      "Epoch: 9/20\n",
      "Train - Loss: 858.8292 Accuracy: 0.6375\n",
      "Valid - Loss: 250.8829 Accuracy: 0.5814\n",
      "Epoch: 10/20\n",
      "Train - Loss: 822.6898 Accuracy: 0.6489\n",
      "Valid - Loss: 256.8684 Accuracy: 0.5750\n",
      "Epoch: 11/20\n",
      "Train - Loss: 788.2360 Accuracy: 0.6635\n",
      "Valid - Loss: 246.2649 Accuracy: 0.5960\n",
      "Epoch: 12/20\n",
      "Train - Loss: 760.0568 Accuracy: 0.6765\n",
      "Valid - Loss: 250.8255 Accuracy: 0.5850\n",
      "Epoch: 13/20\n",
      "Train - Loss: 730.0558 Accuracy: 0.6863\n",
      "Valid - Loss: 253.4429 Accuracy: 0.5939\n",
      "Epoch: 14/20\n",
      "Train - Loss: 703.0686 Accuracy: 0.6980\n",
      "Valid - Loss: 260.1723 Accuracy: 0.5915\n",
      "Epoch: 15/20\n",
      "Train - Loss: 673.9705 Accuracy: 0.7102\n",
      "Valid - Loss: 265.1057 Accuracy: 0.5965\n",
      "Epoch: 16/20\n",
      "Train - Loss: 647.7692 Accuracy: 0.7218\n",
      "Valid - Loss: 264.4757 Accuracy: 0.5964\n",
      "Epoch: 17/20\n",
      "Train - Loss: 635.4148 Accuracy: 0.7245\n",
      "Valid - Loss: 268.3890 Accuracy: 0.5977\n",
      "Epoch: 18/20\n",
      "Train - Loss: 613.6016 Accuracy: 0.7360\n",
      "Valid - Loss: 270.9255 Accuracy: 0.5908\n",
      "Epoch: 19/20\n",
      "Train - Loss: 596.4606 Accuracy: 0.7423\n",
      "Valid - Loss: 274.8234 Accuracy: 0.5861\n",
      "Epoch: 20/20\n",
      "Train - Loss: 582.5017 Accuracy: 0.7492\n",
      "Valid - Loss: 284.6227 Accuracy: 0.5899\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc151f-01d5-4253-8dd8-72173d6545ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
