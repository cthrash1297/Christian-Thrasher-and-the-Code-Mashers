{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "786b0ea3-8b47-4a2e-b4d1-2237672a9a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /opt/conda/lib/python3.11/site-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from opendatasets) (4.67.1)\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.11/site-packages (from opendatasets) (1.7.4.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from opendatasets) (8.1.7)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (6.1.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (3.4.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (3.10)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (4.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (69.5.1)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (2.2.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (2.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.5.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets\n",
    "!pip install pandas\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8d80011a-6c88-496c-aa85-a3870b1e0528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./fer2013\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od \n",
    "import pandas \n",
    "\n",
    "od.download( \n",
    "    \"https://www.kaggle.com/datasets/msambare/fer2013/data\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "99b784d2-9cb0-4444-bec2-ef5e2fae3335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the files in the downloaded folder\n",
    "dataset_path = \"fer2013\"\n",
    "os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "31a33c57-7173-41dc-a532-12aa01c3baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Checking if CUDA is available\n",
    "flag_cuda = torch.cuda.is_available()\n",
    "\n",
    "if not flag_cuda:\n",
    "    print('Using CPU')\n",
    "else:\n",
    "    print('Using GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a8d29c84-49a3-478a-bd30-4d98218318b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 28709\n",
      "    Root location: fer2013/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random as random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Grayscale(num_output_channels=1),  # Ensure single-channel grayscale\n",
    "#     transforms.Resize((48, 48)),  # Resize to match FER2013 dimensions\n",
    "#     transforms.ToTensor(),  # Convert PIL image to PyTorch tensor ✅\n",
    "#     transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize pixel values\n",
    "# ])\n",
    "\n",
    "# valid_transform = transforms.Compose([\n",
    "#     transforms.Grayscale(num_output_channels=1),  # Ensure single-channel grayscale\n",
    "#     transforms.Resize((48, 48)),  # Resize to match FER2013 dimensions\n",
    "#     transforms.ToTensor(),  # Convert PIL image to PyTorch tensor ✅\n",
    "#     transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize pixel values\n",
    "# ])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "    \n",
    "])\n",
    "\n",
    "# Load full training set\n",
    "full_dataset = datasets.ImageFolder(root=\"fer2013/train\", transform=transform)\n",
    "\n",
    "print(full_dataset)\n",
    "\n",
    "# Split 80/20\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "valid_size = len(full_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Test set\n",
    "test_dataset = datasets.ImageFolder(root=\"fer2013/test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d2db774f-3b67-44ef-ae02-ace182407ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "# batch_size = 32\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "074954f7-8544-4bbe-9978-3b268074e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get dataset sizes\n",
    "# train_N = len(train_dataset)\n",
    "# valid_N = len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "458f763d-5f24-4436-a58f-a02d716943ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "n_classes = 7  # FER2013 has 7 emotions\n",
    "IMG_CHS = 1  # Grayscale images\n",
    "kernel_size = 3\n",
    "flattened_img_size = 75 * 3 * 3\n",
    "\n",
    "# Define the CNN Model\n",
    "model = nn.Sequential(\n",
    "    # First convolution\n",
    "    nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1),  # 25 x 48 x 48\n",
    "    nn.BatchNorm2d(25),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),  # 25 x 24 x 24\n",
    "    \n",
    "    # Second convolution\n",
    "    nn.Conv2d(25, 50, kernel_size, stride=1, padding=1),  # 50 x 24 x 24\n",
    "    nn.BatchNorm2d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.MaxPool2d(2, stride=2),  # 50 x 12 x 12\n",
    "    \n",
    "    # Third convolution\n",
    "    nn.Conv2d(50, 75, kernel_size, stride=1, padding=1),  # 75 x 12 x 12\n",
    "    nn.BatchNorm2d(75),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.MaxPool2d(2, stride=2),  # 75 x 6 x 6\n",
    "    \n",
    "    # Flatten to Dense\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(75 * 6 * 6, 512),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, n_classes)  # Output 7 classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9818666d-f5e1-4c25-9887-5fde6c377cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if flag_cuda else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "25169d9b-d62f-4693-9b16-f6fac8cda1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ab039a74-e60e-4692-92ce-87f517faeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate batch accuracy\n",
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "838da5b6-f4cc-42fc-b6e6-5e0bd7772bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    valid_N = len(valid_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    \n",
    "    print(f'Valid - Loss: {loss:.4f} Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "76a84054-e67f-404b-a2af-43a89438a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    train_N = len(train_loader.dataset)\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    \n",
    "    print(f'Train - Loss: {loss:.4f} Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0c6809cf-e0d5-4aa4-9275-58e8dccfa4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "def compute_f1():\n",
    "    model.eval()\n",
    "    f1_metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=7).to(\"cuda\")\n",
    "    f1_metric.reset()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)  # Keep everything on GPU\n",
    "            output = model(x)\n",
    "            predictions = torch.argmax(output, dim=1)\n",
    "\n",
    "            f1_metric.update(predictions, y)  # Directly update the metric\n",
    "    print(f\"F1_score: {f1_metric.compute().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "49bd1257-7ec4-4672-bf87-10a3cd085d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n",
      "Train - Loss: 598.9866 Accuracy: 0.3469\n",
      "Valid - Loss: 136.6679 Accuracy: 0.4441\n",
      "F1_score: 0.4441\n",
      "Epoch: 2/20\n",
      "Train - Loss: 514.4733 Accuracy: 0.4467\n",
      "Valid - Loss: 122.6078 Accuracy: 0.4906\n",
      "F1_score: 0.4906\n",
      "Epoch: 3/20\n",
      "Train - Loss: 478.4685 Accuracy: 0.4884\n",
      "Valid - Loss: 115.5131 Accuracy: 0.5024\n",
      "F1_score: 0.5024\n",
      "Epoch: 4/20\n",
      "Train - Loss: 456.7639 Accuracy: 0.5140\n",
      "Valid - Loss: 112.3119 Accuracy: 0.5204\n",
      "F1_score: 0.5204\n",
      "Epoch: 5/20\n",
      "Train - Loss: 436.8511 Accuracy: 0.5367\n",
      "Valid - Loss: 109.6250 Accuracy: 0.5366\n",
      "F1_score: 0.5366\n",
      "Epoch: 6/20\n",
      "Train - Loss: 421.3740 Accuracy: 0.5575\n",
      "Valid - Loss: 106.9106 Accuracy: 0.5524\n",
      "F1_score: 0.5524\n",
      "Epoch: 7/20\n",
      "Train - Loss: 410.6085 Accuracy: 0.5675\n",
      "Valid - Loss: 106.9850 Accuracy: 0.5458\n",
      "F1_score: 0.5458\n",
      "Epoch: 8/20\n",
      "Train - Loss: 396.8216 Accuracy: 0.5780\n",
      "Valid - Loss: 104.6621 Accuracy: 0.5543\n",
      "F1_score: 0.5543\n",
      "Epoch: 9/20\n",
      "Train - Loss: 384.3249 Accuracy: 0.5904\n",
      "Valid - Loss: 102.8100 Accuracy: 0.5594\n",
      "F1_score: 0.5594\n",
      "Epoch: 10/20\n",
      "Train - Loss: 374.8081 Accuracy: 0.5999\n",
      "Valid - Loss: 102.5147 Accuracy: 0.5681\n",
      "F1_score: 0.5681\n",
      "Epoch: 11/20\n",
      "Train - Loss: 364.6078 Accuracy: 0.6127\n",
      "Valid - Loss: 101.9252 Accuracy: 0.5674\n",
      "F1_score: 0.5674\n",
      "Epoch: 12/20\n",
      "Train - Loss: 351.5655 Accuracy: 0.6246\n",
      "Valid - Loss: 100.6997 Accuracy: 0.5707\n",
      "F1_score: 0.5707\n",
      "Epoch: 13/20\n",
      "Train - Loss: 343.8797 Accuracy: 0.6360\n",
      "Valid - Loss: 100.1571 Accuracy: 0.5747\n",
      "F1_score: 0.5747\n",
      "Epoch: 14/20\n",
      "Train - Loss: 333.6899 Accuracy: 0.6463\n",
      "Valid - Loss: 100.3906 Accuracy: 0.5819\n",
      "F1_score: 0.5819\n",
      "Epoch: 15/20\n",
      "Train - Loss: 327.4840 Accuracy: 0.6512\n",
      "Valid - Loss: 101.1872 Accuracy: 0.5805\n",
      "F1_score: 0.5805\n",
      "Epoch: 16/20\n",
      "Train - Loss: 315.0186 Accuracy: 0.6619\n",
      "Valid - Loss: 100.1134 Accuracy: 0.5820\n",
      "F1_score: 0.5820\n",
      "Epoch: 17/20\n",
      "Train - Loss: 310.9140 Accuracy: 0.6668\n",
      "Valid - Loss: 99.6319 Accuracy: 0.5806\n",
      "F1_score: 0.5806\n",
      "Epoch: 18/20\n",
      "Train - Loss: 302.0156 Accuracy: 0.6751\n",
      "Valid - Loss: 100.4626 Accuracy: 0.5850\n",
      "F1_score: 0.5850\n",
      "Epoch: 19/20\n",
      "Train - Loss: 296.1400 Accuracy: 0.6826\n",
      "Valid - Loss: 99.7959 Accuracy: 0.5899\n",
      "F1_score: 0.5899\n",
      "Epoch: 20/20\n",
      "Train - Loss: 287.8802 Accuracy: 0.6891\n",
      "Valid - Loss: 100.2505 Accuracy: 0.5829\n",
      "F1_score: 0.5829\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}/{epochs}')\n",
    "    train()\n",
    "    validate()\n",
    "    compute_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc151f-01d5-4253-8dd8-72173d6545ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe444b8-3189-40f3-bccc-a8bb19fa9642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef27c67-1cbe-4937-b7e6-4cc19507ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
